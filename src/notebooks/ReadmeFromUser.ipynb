{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bba688a-5491-43d2-84d9-1bd275b99959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working dir/Volumes/Zarif/myStuff/research/repoPaper/src\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os, sys\n",
    "exec(open(\"init_notebook.py\").read())\n",
    "from DataTools import DataTools\n",
    "from RepoTools import RepoTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2f594bd-287f-41ed-a0fe-a74e3198b9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea6598c2-6066-4244-ac2f-41fa763d3cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 0/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█████████████▌                                                      | 1/5 [00:00<00:02,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███████████████████████████▏                                        | 2/5 [00:01<00:02,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████▊                           | 3/5 [00:02<00:01,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████▍             | 4/5 [00:03<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 5/5 [00:03<00:00,  1.35it/s]\n"
     ]
    }
   ],
   "source": [
    "user = RepoTools.github.get_user(\"amzn\")\n",
    "repos = RepoTools.getReposFromUser(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51d85ff2-40c1-4637-8f63-825791afd6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 132/132 [01:02<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "repoWithReadmes = RepoTools.getRepoWithReadmes(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "369c489b-542f-441e-9f4e-1a79ff6199e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "RepoTools.saveAsPickle(repoWithReadmes, \"amazonRepoWithReadMe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "768cfb6a-3c25-45a0-a30f-eb3d1117ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repoWithReadmes = RepoTools.loadPickle(\"amazonRepoWithReadMe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "2c1b076e-02e1-4a1b-befc-6344405fc95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{SDR}: Efficient Neural Re-ranking using Succinct DocumentRepresentation\n",
      "Studying the Effectiveness of\\xc2\\xa0Conversational Search Refinement Through User Simulation\n",
      "A First Look: Towards Explainable {T}ext{VQA} Models via Visual and Textual Explanations\n",
      "Misspelling Detection from Noisy Product Images\n",
      "{C}ycle{KQR}: Unsupervised Bidirectional Keyword-Question Rewriting\n",
      "Answering Ambiguous Questions through Generative Evidence Fusion and Round-Trip Prediction\n",
      "&quot;Pascal&quot;\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# bibtex_pattern = r'@\\w+\\{(.*?)\\}'\n",
    "# title_pattern = r'\\[(.*?)\\b(paper|Paper)\\b(.*?)\\]'\n",
    "tp2 = r'title={\\s*(\\S[^\\n\\r\\}]*)'\n",
    "tp1 = r'title\\s*=\\s*\"([^\"]+\\s*)+\"'\n",
    "\n",
    "for i, repoWithReadme in enumerate(repoWithReadmes):\n",
    "    rm = str(repoWithReadme[\"readme\"].decoded_content)\n",
    "    \n",
    "    # bibtex_matches = re.findall(bibtex_pattern, rm, re.DOTALL)\n",
    "    title_matches = re.findall(tp1, rm)\n",
    "    titles = [match.strip() for match in title_matches]\n",
    "    # if len(bibtex_matches) > 0:\n",
    "    #     print(bibtex_matches)\n",
    "    \n",
    "    if len(title_matches) > 0:\n",
    "        print(titles[0])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "20d3b4de-bbd2-44f1-a511-0e27bdaced52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data\n",
      "Learning to Bid with AuctionGym\n",
      "Efficient Learning on Point Clouds With Basis Point Sets\n",
      "ScrabbleGAN: Semi-Supervised Varying Length Handwritten Text Generation\n",
      "Debiased balanced interleaving at Amazon Search\n",
      "Automatic Discovery of Privacy--Utility Pareto Fronts\n",
      "Learning Attribute-driven Disentangled Representations for Interactive Fashion Retrieval\n",
      "Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers and Self-supervised Learning\n",
      "Learning Multimodal Affinities for Textual Editing in Images\n",
      "RETE: Retrieval-Enhanced Temporal Event Forecasting on Unified Query Product Evolutionary Graph\n",
      "Multilingual Knowledge Graph Completion with Self-Supervised\\nAdaptive Graph Alignment\n",
      "Transformer uncertainty estimation with hierarchical stochastic attention\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# bibtex_pattern = r'@\\w+\\{(.*?)\\}'\n",
    "# title_pattern = r'\\[(.*?)\\b(paper|Paper)\\b(.*?)\\]'\n",
    "tp2 = r'title\\s*=\\s*{([^}]+\\s*)+}'\n",
    "# tp1 = r'title\\s*=\\s*\"([^\"]+\\s*)+\"'\n",
    "\n",
    "for i, repoWithReadme in enumerate(repoWithReadmes):\n",
    "    rm = str(repoWithReadme[\"readme\"].decoded_content)\n",
    "    \n",
    "    # bibtex_matches = re.findall(bibtex_pattern, rm, re.DOTALL)\n",
    "    title_matches = re.findall(tp2, rm)\n",
    "    titles = [match.strip() for match in title_matches]\n",
    "    # if len(bibtex_matches) > 0:\n",
    "    #     print(bibtex_matches)\n",
    "    \n",
    "    if len(title_matches) > 0:\n",
    "        print(titles[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "29d50dcb-16f0-4ca5-8d31-8625c0634d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/amzn/amazon-succinct-doc-representation\n",
      "https://github.com/amzn/amazon-weak-ner-needle\n",
      "https://github.com/amzn/auction-gym\n",
      "https://github.com/amzn/basis-point-sets\n",
      "https://github.com/amzn/convolutional-handwriting-gan\n",
      "https://github.com/amzn/debiased-balanced-interleaving\n",
      "https://github.com/amzn/differential-privacy-bayesian-optimization\n",
      "https://github.com/amzn/explainable-text-vqa\n",
      "https://github.com/amzn/fashion-attribute-disentanglement\n",
      "https://github.com/amzn/image-misspell-coling2020\n",
      "https://github.com/amzn/image-to-recipe-transformers\n",
      "https://github.com/amzn/kqr\n",
      "https://github.com/amzn/multimodal-affinities\n",
      "https://github.com/amzn/refuel-open-domain-qa\n",
      "https://github.com/amzn/rete-thewebconf-2022\n",
      "https://github.com/amzn/ss-aga-kgc\n",
      "https://github.com/amzn/sto-transformer\n"
     ]
    }
   ],
   "source": [
    "for i, repoWithReadme in enumerate(repoWithReadmes):\n",
    "    rm = str(repoWithReadme[\"readme\"].decoded_content)\n",
    "    \n",
    "    if '@inproceedings' in rm or '@article' in rm or '@misc' in rm:\n",
    "        print('https://github.com/' + repoWithReadme['repo'].full_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1c03cb9-209b-4c78-821b-673d4b26d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "title_patterns = [r'title\\s*=\\s*{([^}]+\\s*)+}', r'title\\s*=\\s*\"([^\"]+\\s*)+\"']\n",
    "paperWithRepoURLs = []\n",
    "for repoWithReadme in enumerate(repoWithReadmes):\n",
    "    rm = str(repoWithReadme[\"readme\"].decoded_content.decode(\"utf-8\"))\n",
    "    repoName = repoWithReadme['repo'].full_name\n",
    "    for title_pattern in title_patterns:\n",
    "        title_matches = re.findall(title_pattern, rm)\n",
    "        titles = [match.strip() for match in title_matches]\n",
    "        if len(titles) > 0 and len(titles[0]) >0:\n",
    "            paperWithRepoURL = {\"title\":titles[0], \"url\":\"https://github.com/\"+repoName}\n",
    "            paperWithRepoURLs.append(paperWithRepoURL)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "05ffb44a-d0b6-47bc-b7d7-6bdb2605a3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "paperDF = RepoTools.getPaperWithRepoDfFromREADME(repoWithReadmes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2adb2df-8e5a-449a-a145-97b06bbea6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTools.saveDfInCSV(paperDF, \"amazonPapers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9f8bdac2-d8a8-43d4-a90e-e2b61b0a481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 0/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████████▋                                                          | 1/7 [00:00<00:05,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|███████████████████▍                                                | 2/7 [00:01<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|█████████████████████████████▏                                      | 3/7 [00:04<00:06,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|██████████████████████████████████████▊                             | 4/7 [00:04<00:03,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████▌                   | 5/7 [00:05<00:02,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|██████████████████████████████████████████████████████████▎         | 6/7 [00:06<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 7/7 [00:07<00:00,  1.01s/it]\n",
      "100%|████████████████████████████████████████████████████████████████| 195/195 [01:32<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "hehe = RepoTools.savePaperNameFromGithubUser(\"apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b823d678-8d85-479e-b67f-5a46b7f8be79",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTools.saveDfInCSV(hehe, \"applePapers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "586474e2-a252-4631-b0c6-fb266b7a0c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lala = RepoTools.loadPickle(\"appleRepoWithReadme\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "f0a45b42-fc7a-4851-83fb-0133eb41dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "a = []\n",
    "for _ in lala:\n",
    "    rm = str(_[\"readme\"].decoded_content)\n",
    "    if \"paper\" in rm:\n",
    "        a.append(\"https://github.com/\" + _[\"repo\"].full_name)\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c92eec59-616e-47a1-bd8f-24ae0b175744",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(hehe['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c86696fb-feae-48f7-9016-6cbb11319f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/apple/ARKitScenes\n",
      "https://github.com/apple/indexstore-db\n",
      "https://github.com/apple/learning-compressible-subspaces\n",
      "https://github.com/apple/ml-all-pairs\n",
      "https://github.com/apple/ml-code-switched-speech-translation\n",
      "https://github.com/apple/ml-collegial-ensembles\n",
      "https://github.com/apple/ml-covid-mobility\n",
      "https://github.com/apple/ml-cvpr2019-swd\n",
      "https://github.com/apple/ml-envmapnet\n",
      "https://github.com/apple/ml-flair\n",
      "https://github.com/apple/ml-hypersim\n",
      "https://github.com/apple/ml-probabilistic-attention\n",
      "https://github.com/apple/ml-sad\n",
      "https://github.com/apple/ml-shuffling-amplification\n",
      "https://github.com/apple/ml-stuttering-events-dataset\n",
      "https://github.com/apple/ml-transcript-translation-consistency-ratings\n",
      "https://github.com/apple/ml-tree-dst\n",
      "https://github.com/apple/ml-uwac\n",
      "https://github.com/apple/ml-vfi-smiff\n",
      "https://github.com/apple/swift-cluster-membership\n",
      "https://github.com/apple/swift-distributed-tracing-baggage\n",
      "https://github.com/apple/swift-distributed-tracing-baggage-core\n"
     ]
    }
   ],
   "source": [
    "# we check which links were ignored by our regex. and find out why in the next part\n",
    "for _ in a:\n",
    "    if _ not in b:\n",
    "        print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ae735-672b-4150-89c4-f3e9ed2ef296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
